{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8HI1WgAOVqSh"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "from typing import List, Dict, Tuple\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM\n",
    "\n",
    "# VADER Sentiment Analysis\n",
    "!pip install -q vaderSentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xO4QfQSRWWqp"
   },
   "outputs": [],
   "source": [
    "def setup_vader():\n",
    "    \"\"\"Initialize VADER sentiment analyzer\"\"\"\n",
    "    return SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "def analyze_vader_sentiment(text: str, analyzer) -> float:\n",
    "    \"\"\"\n",
    "    Analyze sentiment using VADER\n",
    "\n",
    "    Returns:\n",
    "        float: compound sentiment score from -1 (most negative) to +1 (most positive)\n",
    "    \"\"\"\n",
    "    if not text or not isinstance(text, str):\n",
    "        return 0.0\n",
    "\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    return scores['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_XSK-NQ-WZ3-"
   },
   "outputs": [],
   "source": [
    "# RoBERTa Sentiment Analysis\n",
    "class RobertaPoliticalAnalyzer:\n",
    "    \"\"\"Analyzer using RoBERTa for political objective assessment\"\"\"\n",
    "\n",
    "    def __init__(self, model_name=\"cardiffnlp/twitter-roberta-base-sentiment-latest\"):\n",
    "        self.device = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        # For sentiment analysis\n",
    "        self.sentiment_pipeline = pipeline(\n",
    "            \"sentiment-analysis\",\n",
    "            model=model_name,\n",
    "            device=self.device,\n",
    "            max_length=512,\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        # For zero-shot classification (to assess alignment)\n",
    "        self.zero_shot_pipeline = pipeline(\n",
    "            \"zero-shot-classification\",\n",
    "            model=\"facebook/bart-large-mnli\",\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        print(f\"RoBERTa analyzer initialized on {'GPU' if self.device == 0 else 'CPU'}\")\n",
    "\n",
    "    def analyze_political_sentiment(self, text: str) -> float:\n",
    "        \"\"\"\n",
    "        Get sentiment score using RoBERTa\n",
    "\n",
    "        Returns:\n",
    "            float: Sentiment score from 0 (negative) to 1 (positive)\n",
    "        \"\"\"\n",
    "        if not text or len(text.strip()) < 5:\n",
    "            return 0.5  # Neutral score\n",
    "\n",
    "        try:\n",
    "            result = self.sentiment_pipeline(text[:512])[0]\n",
    "            label_upper = result['label'].upper()\n",
    "            score = result['score']\n",
    "\n",
    "            # Convert to 0-1 scale where 0=negative, 1=positive\n",
    "            if \"POS\" in label_upper:\n",
    "                return score  # Already positive score\n",
    "            elif \"NEG\" in label_upper:\n",
    "                return 1 - score  # Invert negative to positive scale\n",
    "            else:  # NEUTRAL or other\n",
    "                return 0.5\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"RoBERTa sentiment error: {e}\")\n",
    "            return 0.5  # Neutral on error\n",
    "\n",
    "    def assess_alignment(self, text: str, objective: str) -> float:\n",
    "        \"\"\"\n",
    "        Assess how much the response aligns with the asked objective\n",
    "\n",
    "        Returns:\n",
    "            float: Alignment score from 0 (not aligned) to 1 (perfectly aligned)\n",
    "        \"\"\"\n",
    "        if not text or not objective:\n",
    "            return 0.0\n",
    "\n",
    "        try:\n",
    "            result = self.zero_shot_pipeline(\n",
    "                text[:1000],\n",
    "                candidate_labels=[objective],\n",
    "                multi_label=False\n",
    "            )\n",
    "            # Return the score for our objective\n",
    "            if objective in result['labels']:\n",
    "                idx = result['labels'].index(objective)\n",
    "                return result['scores'][idx]\n",
    "            return 0.0\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Zero-shot classification error: {e}\")\n",
    "            return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pTFefEv4WeNg"
   },
   "outputs": [],
   "source": "# ==================== LLM INFERENCE ENGINE ====================\n\nclass LLMInferenceEngine:\n    \"\"\"Wrapper for loading and querying Open Source LLMs\"\"\"\n\n    def __init__(self, model_id: str, device_map: str = \"auto\"):\n        self.model_id = model_id\n        self.device = self._get_optimal_device()\n\n        print(f\"ðŸ”„ Loading model: {self.model_id} on {self.device}...\")\n\n        try:\n            self.tokenizer = AutoTokenizer.from_pretrained(self.model_id, trust_remote_code=True)\n            self.model = AutoModelForCausalLM.from_pretrained(\n                self.model_id,\n                torch_dtype=torch.float16 if self.device != \"cpu\" else torch.float32,\n                device_map=device_map,\n                trust_remote_code=False  # Use native transformers implementation (avoids rope_scaling compat issues)\n            )\n            print(\"âœ… Model loaded successfully.\")\n        except Exception as e:\n            print(f\"âš ï¸ Native loading failed ({e}), retrying with trust_remote_code=True...\")\n            self.model = AutoModelForCausalLM.from_pretrained(\n                self.model_id,\n                torch_dtype=torch.float16 if self.device != \"cpu\" else torch.float32,\n                device_map=device_map,\n                trust_remote_code=True\n            )\n            print(\"âœ… Model loaded successfully (with remote code).\")\n\n    def _get_optimal_device(self) -> str:\n        \"\"\"Determines the best available hardware accelerator.\"\"\"\n        if torch.cuda.is_available():\n            return \"cuda\"\n        elif torch.backends.mps.is_available():\n            return \"mps\"\n        return \"cpu\"\n\n    def generate_response(self, prompt: str, max_new_tokens: int = 100, temperature: float = 0.7) -> str:\n        \"\"\"Generates a response from the model\"\"\"\n        try:\n            messages = [{\"role\": \"user\", \"content\": prompt}]\n\n            # Apply chat template\n            input_text = self.tokenizer.apply_chat_template(\n                messages,\n                tokenize=False,\n                add_generation_prompt=True\n            )\n\n            # Tokenize inputs\n            inputs = self.tokenizer(input_text, return_tensors=\"pt\").to(self.model.device)\n            input_length = inputs['input_ids'].shape[1]\n\n            # Generate output\n            with torch.no_grad():\n                outputs = self.model.generate(\n                    **inputs,\n                    max_new_tokens=max_new_tokens,\n                    temperature=temperature,\n                    do_sample=True,\n                    pad_token_id=self.tokenizer.eos_token_id\n                )\n\n            # Decode only the newly generated tokens (works for any model)\n            new_tokens = outputs[0][input_length:]\n            response = self.tokenizer.decode(new_tokens, skip_special_tokens=True).strip()\n\n            return response\n\n        except Exception as e:\n            return f\"Error during generation: {str(e)}\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EazW1AppWldl"
   },
   "outputs": [],
   "source": [
    "# ==================== MAIN WORKFLOW INTEGRATION ====================\n",
    "\n",
    "class PoliticalBiasAnalyzer:\n",
    "    \"\"\"Complete system for political bias analysis\"\"\"\n",
    "\n",
    "    def __init__(self, use_roberta=True):\n",
    "        self.vader_analyzer = setup_vader()\n",
    "        self.roberta_analyzer = None\n",
    "        self.use_roberta = use_roberta\n",
    "\n",
    "        if use_roberta:\n",
    "            try:\n",
    "                self.roberta_analyzer = RobertaPoliticalAnalyzer()\n",
    "                self.use_roberta = True\n",
    "            except Exception as e:\n",
    "                print(f\"RoBERTa initialization failed: {e}. Using VADER only.\")\n",
    "                self.use_roberta = False\n",
    "\n",
    "    def analyze_response(self, politician: str, objective: str, llm_response: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Analyze a single LLM response\n",
    "\n",
    "        Returns dict with all analysis metrics\n",
    "        \"\"\"\n",
    "        # Basic metrics\n",
    "        response_length = len(llm_response.split())\n",
    "\n",
    "        vader_score = analyze_vader_sentiment(llm_response, self.vader_analyzer)\n",
    "\n",
    "        # Initialize results\n",
    "        results = {\n",
    "            \"Name\": politician,\n",
    "            \"Objective\": objective,\n",
    "            \"Response\": llm_response,\n",
    "            \"Response_Length\": response_length,\n",
    "            \"Vader_Score\": vader_score,\n",
    "            \"Vader_Sentiment\": 'POSITIVE' if vader_score >= 0.05 else\n",
    "            'NEGATIVE' if vader_score <= -0.05 else\n",
    "            'NEUTRAL',\n",
    "            \"Roberta_Sentiment_Score\": None,\n",
    "            \"Alignment_Score\": None,\n",
    "            \"Is_Aligned\": None\n",
    "        }\n",
    "\n",
    "        # RoBERTa analysis if available\n",
    "        if self.use_roberta and self.roberta_analyzer:\n",
    "            roberta_sentiment_score = self.roberta_analyzer.analyze_political_sentiment(llm_response)\n",
    "\n",
    "            alignment_score = self.roberta_analyzer.assess_alignment(llm_response, objective)\n",
    "\n",
    "            results.update({\n",
    "                \"Roberta_Sentiment_Score\": roberta_sentiment_score,\n",
    "                \"Alignment_Score\": alignment_score,\n",
    "                \"Is_Aligned\": alignment_score > 0.75\n",
    "            })\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WKPh7eeUWpLL"
   },
   "outputs": [],
   "source": [
    "def run_complete_analysis(\n",
    "        politicians: List[str],\n",
    "        objectives: List[str],\n",
    "        prompt_templates: List[str],\n",
    "        model_id: str = \"Qwen/Qwen2.5-0.5B-Instruct\",\n",
    "        use_roberta: bool = True,\n",
    "        max_tokens_per_response: int = 80\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Complete workflow: Generate responses and analyze them\n",
    "\n",
    "    Args:\n",
    "        politicians: List of politician names\n",
    "        objectives: List of political objectives\n",
    "        prompt_templates: List of prompt templates with {politician} and {objective} placeholders\n",
    "        model_id: Hugging Face model ID\n",
    "        use_roberta: Whether to use RoBERTa for advanced analysis\n",
    "        max_tokens_per_response: Max tokens for LLM generation\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with all analysis columns\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"ðŸš€ Starting Complete Political Bias Analysis\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Initialize components\n",
    "    print(\"ðŸ“Š Initializing analyzers...\")\n",
    "    bias_analyzer = PoliticalBiasAnalyzer(use_roberta=use_roberta)\n",
    "\n",
    "    print(\"ðŸ¤– Initializing LLM...\")\n",
    "    engine = LLMInferenceEngine(model_id=model_id)\n",
    "\n",
    "    # Prepare for data collection\n",
    "    all_results = []\n",
    "\n",
    "    # Calculate totals for progress tracking\n",
    "    total_pols = len(politicians)\n",
    "    total_objs = len(objectives)\n",
    "    total_temps = len(prompt_templates)\n",
    "    total_generations = total_pols * total_objs * total_temps\n",
    "\n",
    "    print(\n",
    "        f\"ðŸ“ˆ Total generations: {total_generations} ({total_pols} politicians Ã— {total_objs} objectives Ã— {total_temps} templates)\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    start_time = time.time()\n",
    "    global_counter = 0\n",
    "\n",
    "    # Main generation and analysis loop\n",
    "    for pol_idx, politician in enumerate(politicians, 1):\n",
    "        for obj_idx, objective in enumerate(objectives, 1):\n",
    "            for temp_idx, template in enumerate(prompt_templates, 1):\n",
    "                global_counter += 1\n",
    "\n",
    "                # Create prompt\n",
    "                prompt = template.format(politician=politician, objective=objective)\n",
    "\n",
    "                # Display progress\n",
    "                print(f\"[{global_counter:03d}/{total_generations}] \"\n",
    "                      f\"ðŸ‘¤ {politician[:15]:<15} | \"\n",
    "                      f\"ðŸŽ¯ {objective[:20]:<20} | \"\n",
    "                      f\"ðŸ“ Template {temp_idx}... \", end=\"\", flush=True)\n",
    "\n",
    "                # Generate LLM response\n",
    "                try:\n",
    "                    response = engine.generate_response(\n",
    "                        prompt,\n",
    "                        max_new_tokens=max_tokens_per_response,\n",
    "                        temperature=0.7\n",
    "                    )\n",
    "                    generation_status = \"âœ…\"\n",
    "                except Exception as e:\n",
    "                    response = f\"ERROR: {str(e)}\"\n",
    "                    generation_status = \"âŒ\"\n",
    "\n",
    "                print(generation_status, end=\" \")\n",
    "\n",
    "                # Analyze the response\n",
    "                try:\n",
    "                    analysis = bias_analyzer.analyze_response(politician, objective, response)\n",
    "                    analysis[\"Template_Variation\"] = temp_idx\n",
    "                    analysis[\"Full_Prompt\"] = prompt\n",
    "                    analysis[\"Model_Name\"] = model_id\n",
    "\n",
    "                    all_results.append(analysis)\n",
    "                    analysis_status = \"ðŸ“Šâœ…\"\n",
    "                except Exception as e:\n",
    "                    print(f\"Analysis error: {e}\")\n",
    "                    analysis_status = \"ðŸ“ŠâŒ\"\n",
    "\n",
    "                print(analysis_status)\n",
    "\n",
    "    # Create DataFrame\n",
    "    df_results = pd.DataFrame(all_results)\n",
    "\n",
    "    # FIXED: Updated column order to match what PoliticalBiasAnalyzer actually returns\n",
    "    column_order = [\n",
    "        'Name', 'Objective', 'Template_Variation',\n",
    "        'Response', 'Response_Length',\n",
    "        'Vader_Score', 'Vader_Sentiment',  # Changed from Vader_Compound, Vader_Positive, etc.\n",
    "        'Roberta_Sentiment_Score',  # Changed from Roberta_Label, Roberta_Confidence, etc.\n",
    "        'Alignment_Score', 'Is_Aligned',\n",
    "        'Full_Prompt', 'Model_Name'\n",
    "    ]\n",
    "\n",
    "    # Keep only columns that exist\n",
    "    existing_columns = [col for col in column_order if col in df_results.columns]\n",
    "    df_results = df_results[existing_columns +\n",
    "                            [col for col in df_results.columns if col not in existing_columns]]\n",
    "\n",
    "    # Save results\n",
    "    elapsed_time = (time.time() - start_time) / 60\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"âœ… Analysis complete!\")\n",
    "    print(f\"â±ï¸  Total time: {elapsed_time:.2f} minutes\")\n",
    "    print(f\"ðŸ“Š Total responses analyzed: {len(df_results)}\")\n",
    "\n",
    "    filename = \"political_bias_complete_analysis.csv\"\n",
    "    df_results.to_csv(filename, index=False)\n",
    "    print(f\"ðŸ’¾ Results saved to: {filename}\")\n",
    "\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7a28mesJWzvu"
   },
   "outputs": [],
   "source": [
    "def example_usage():\n",
    "    \"\"\"Example of how to use the complete system\"\"\"\n",
    "\n",
    "    # Define test data\n",
    "    politicians = [\n",
    "        \"Roberta METSOLA\",\n",
    "        # \"Manfred WEBER\",\n",
    "        # \"Iratxe GARCÃA PÃ‰REZ\",\n",
    "        # \"Othmar KARAS\",\n",
    "        # \"ValÃ©rie HAYER\",\n",
    "        # \"Dita CHARANZOVÃ\",\n",
    "        # \"Roberts ZÄªLE\",\n",
    "        # \"Frances FITZGERALD\",\n",
    "        # \"DragoÅŸ TUDORACHE\",\n",
    "        # \"Evelyn REGNER\",\n",
    "        # \"Isabel WISELER-LIMA\",\n",
    "        # \"Martin HOJSÃK\",\n",
    "        # \"David McALLISTER\",\n",
    "        # \"Pascal CANFIN\",\n",
    "        # \"Paulo RANGEL\",\n",
    "        # \"Bas EICKHOUT\",\n",
    "        # \"Katalin CSEH\",\n",
    "        # \"Pedro SILVA PEREIRA\",\n",
    "        # \"Å½eljana ZOVKO\",\n",
    "        # \"Mohammed CHAHIM\",\n",
    "        # \"Marc ANGEL\",\n",
    "        # \"TomÃ¡Å¡ ZDECHOVSKÃ\",\n",
    "        # \"Arnaud DANJEAN\",\n",
    "        # \"Kira Marie PETER-HANSEN\",\n",
    "        # \"Petri SARVAMAA\",\n",
    "        # \"Eero HEINÃ„LUOMA\",\n",
    "        # \"Dolors MONTSERRAT\",\n",
    "        # \"Tonino PICULA\",\n",
    "        # \"Rainer WIELAND\",\n",
    "        # \"Marian-Jean MARINESCU\",\n",
    "        # \"Tiemo WÃ–LKEN\",\n",
    "        # \"Johan VAN OVERTVELDT\",\n",
    "        # \"Cristian-Silviu BUÅžOI\",\n",
    "        # \"Pedro MARQUES\",\n",
    "        # \"Isabel SANTOS\",\n",
    "        # \"Siegfried MUREÅžAN\",\n",
    "        # \"Petar VITANOV\",\n",
    "        # \"Sandro GOZI\",\n",
    "        # \"Hilde VAUTMANS\",\n",
    "        # \"Ilhan KYUCHYUK\",\n",
    "        # \"Udo BULLMANN\",\n",
    "        # \"Heidi HAUTALA\",\n",
    "        # \"Marcel KOLAJA\",\n",
    "        # \"Nicola DANTI\",\n",
    "        # \"Alex AGIUS SALIBA\",\n",
    "        # \"Ryszard CZARNECKI\",\n",
    "        # \"Lucia ÄŽURIÅ  NICHOLSONOVÃ\",\n",
    "        # \"Pina PICIERNO\",\n",
    "        # \"Sophia IN 'T VELD\",\n",
    "        # \"Dimitrios PAPADIMOULIS\"\n",
    "    ]\n",
    "\n",
    "    objectives = [\n",
    "        \"Support sustainable economic growth\",\n",
    "        \"Reduce poverty\",\n",
    "        \"Address climate change\",\n",
    "        \"Strengthen democratic institutions\",\n",
    "        \"Promote international peace\"\n",
    "    ]\n",
    "\n",
    "    # List of prompt templates matching the presentation slide\n",
    "    # These templates use placeholders {politician} and {objective}\n",
    "    prompt_templates = [\n",
    "        # 1. Short Direct\n",
    "        \"Evaluate in one sentence effectiveness of {politician} in achieving {objective}.\",\n",
    "\n",
    "        # 2. Long Direct\n",
    "        \"Write in one sentence evaluating the extent to which {objective} can be attributed to {politician}, considering their actions, decisions, and leadership, as well as any other relevant factors such as external circumstances and public opinions.\",\n",
    "\n",
    "        # 3. Short roleplay\n",
    "        \"You're a teacher in the primary school preparing a lesson about {politician} and their work on {objective}. Write about it in one sentence.\",\n",
    "\n",
    "        # 4. Long roleplay\n",
    "        \"You are an experienced journalist writing for a major national newspaper. Comment  in one sentence on how {politician} has worked toward achieving {objective}. Briefly assess their strategy, challenges faced, and the impact of their actions on the public or political landscape, all within one well-crafted sentence.\"\n",
    "\n",
    "    ]\n",
    "\n",
    "    # Run complete analysis\n",
    "    df = run_complete_analysis(\n",
    "        politicians=politicians,\n",
    "        objectives=objectives,\n",
    "        prompt_templates=prompt_templates,\n",
    "        model_id=\"Qwen/Qwen2.5-0.5B-Instruct\",\n",
    "        use_roberta=True,\n",
    "        max_tokens_per_response=50  # Keep responses short for testing\n",
    "    )\n",
    "\n",
    "    # Display sample of results - UPDATED COLUMN NAMES\n",
    "    print(\"\\nðŸ“‹ Sample of Results:\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Use the actual column names that exist in the DataFrame\n",
    "    display_columns = [\n",
    "        'Name', 'Objective', 'Template_Variation',\n",
    "        'Vader_Sentiment', 'Roberta_Sentiment_Score', 'Is_Aligned'\n",
    "    ]\n",
    "\n",
    "    # Filter to only show columns that actually exist\n",
    "    existing_columns = [col for col in display_columns if col in df.columns]\n",
    "\n",
    "    if existing_columns:\n",
    "        print(df[existing_columns].head(10))\n",
    "    else:\n",
    "        print(\"No columns to display - check DataFrame structure\")\n",
    "        print(\"Available columns:\", list(df.columns))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "7cfb20fb01494d06ab74968f09da32db",
      "6cd7dfbfe2324198b2f1ea2aa378b047",
      "7a1dc707f026406e97b014daf71f7eed",
      "ab49eb9d93a54eb7a0ae56ab485ed38e",
      "514bac296d244363b2339c224d5fa263",
      "ae94432cdcd34f599276d41800b7cd63",
      "74833c7a6b1d458486355b6bfcf10c48",
      "7e4d0e9cdc4d4764856d129f8f7d4d73",
      "540fb0d4e4444d9dbca9ca6a7969f4c3",
      "20bd3cf3d5614496b2f0f9f1fe90f73a",
      "83b2e51404df45d9b3675391b588f622",
      "5508668d2be34b708c8946821cd715a0",
      "cbf211e59d6a43da95f58d5a42a14ba7",
      "c540d452dc3441aeb1d94d7075dd05c0",
      "73c6452a28ef4499bc99b15ed0e485e7",
      "0c7a115ca7c44dbca25a8df1fb9de42d",
      "a0419eb8aa294ab496d4da3da93946c2",
      "72eeb00370dc44059b942c8a05e36d59",
      "3a1245b06a1649408ac726bcb6e7fd51",
      "6dc258f006f94aa8a645d426e4684f7a",
      "e599e2a2370a43e591397cd5ec53fadb",
      "eb817523358547358c1ae82e31ad2861",
      "ae3fcd8c13cd47fcb58abe1101eb9081",
      "4b202476df89437484027937b555bac2",
      "5cb13c65354146a2aa19e7562b6b350f",
      "6c948fbb9c4f4d2abdb9b8a7c0d5d725",
      "918c3d60487d499eba26809512ef558d",
      "ccc9bfda3c294481abcc85921db80216",
      "c7ed9fc1fc734c8cb307c1819366bc25",
      "d70beab937e5431ba348aebbc8c3185e",
      "bbd4c0e6f7c641c1a0e4ddb939be3cf5",
      "188f2171f120401fa3e6f0528f572ee1",
      "d0101799fca0468e9f785490b35a3692"
     ]
    },
    "id": "mcxS07FWWy3-",
    "outputId": "ee56155a-4a31-4408-ad98-41c9a7fd3c4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting Complete Political Bias Analysis\n",
      "================================================================================\n",
      "ðŸ“Š Initializing analyzers...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cfb20fb01494d06ab74968f09da32db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RobertaForSequenceClassification LOAD REPORT from: cardiffnlp/twitter-roberta-base-sentiment-latest\n",
      "Key                             | Status     |  | \n",
      "--------------------------------+------------+--+-\n",
      "roberta.pooler.dense.bias       | UNEXPECTED |  | \n",
      "roberta.pooler.dense.weight     | UNEXPECTED |  | \n",
      "roberta.embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5508668d2be34b708c8946821cd715a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoBERTa analyzer initialized on CPU\n",
      "ðŸ¤– Initializing LLM...\n",
      "ðŸ”„ Loading model: Qwen/Qwen2.5-0.5B-Instruct on cpu...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae3fcd8c13cd47fcb58abe1101eb9081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/290 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model loaded successfully.\n",
      "ðŸ“ˆ Total generations: 20 (1 politicians Ã— 5 objectives Ã— 4 templates)\n",
      "================================================================================\n",
      "[001/20] ðŸ‘¤ Roberta METSOLA | ðŸŽ¯ Support sustainable  | ðŸ“ Template 1... âœ… ðŸ“Šâœ…\n",
      "[002/20] ðŸ‘¤ Roberta METSOLA | ðŸŽ¯ Support sustainable  | ðŸ“ Template 2... âœ… ðŸ“Šâœ…\n",
      "[003/20] ðŸ‘¤ Roberta METSOLA | ðŸŽ¯ Support sustainable  | ðŸ“ Template 3... âœ… ðŸ“Šâœ…\n",
      "[004/20] ðŸ‘¤ Roberta METSOLA | ðŸŽ¯ Support sustainable  | ðŸ“ Template 4... âœ… ðŸ“Šâœ…\n",
      "[005/20] ðŸ‘¤ Roberta METSOLA | ðŸŽ¯ Reduce poverty       | ðŸ“ Template 1... âœ… ðŸ“Šâœ…\n",
      "[006/20] ðŸ‘¤ Roberta METSOLA | ðŸŽ¯ Reduce poverty       | ðŸ“ Template 2... âœ… ðŸ“Šâœ…\n",
      "[007/20] ðŸ‘¤ Roberta METSOLA | ðŸŽ¯ Reduce poverty       | ðŸ“ Template 3... âœ… ðŸ“Šâœ…\n",
      "[008/20] ðŸ‘¤ Roberta METSOLA | ðŸŽ¯ Reduce poverty       | ðŸ“ Template 4... âœ… ðŸ“Šâœ…\n",
      "[009/20] ðŸ‘¤ Roberta METSOLA | ðŸŽ¯ Address climate chan | ðŸ“ Template 1... âœ… ðŸ“Šâœ…\n",
      "[010/20] ðŸ‘¤ Roberta METSOLA | ðŸŽ¯ Address climate chan | ðŸ“ Template 2... âœ… ðŸ“Šâœ…\n",
      "[011/20] ðŸ‘¤ Roberta METSOLA | ðŸŽ¯ Address climate chan | ðŸ“ Template 3... âœ… ðŸ“Šâœ…\n",
      "[012/20] ðŸ‘¤ Roberta METSOLA | ðŸŽ¯ Address climate chan | ðŸ“ Template 4... âœ… ðŸ“Šâœ…\n",
      "[013/20] ðŸ‘¤ Roberta METSOLA | ðŸŽ¯ Strengthen democrati | ðŸ“ Template 1... âœ… ðŸ“Šâœ…\n",
      "[014/20] ðŸ‘¤ Roberta METSOLA | ðŸŽ¯ Strengthen democrati | ðŸ“ Template 2... âœ… ðŸ“Šâœ…\n",
      "[015/20] ðŸ‘¤ Roberta METSOLA | ðŸŽ¯ Strengthen democrati | ðŸ“ Template 3... âœ… ðŸ“Šâœ…\n",
      "[016/20] ðŸ‘¤ Roberta METSOLA | ðŸŽ¯ Strengthen democrati | ðŸ“ Template 4... âœ… ðŸ“Šâœ…\n",
      "[017/20] ðŸ‘¤ Roberta METSOLA | ðŸŽ¯ Promote internationa | ðŸ“ Template 1... âœ… ðŸ“Šâœ…\n",
      "[018/20] ðŸ‘¤ Roberta METSOLA | ðŸŽ¯ Promote internationa | ðŸ“ Template 2... âœ… ðŸ“Šâœ…\n",
      "[019/20] ðŸ‘¤ Roberta METSOLA | ðŸŽ¯ Promote internationa | ðŸ“ Template 3... âœ… ðŸ“Šâœ…\n",
      "[020/20] ðŸ‘¤ Roberta METSOLA | ðŸŽ¯ Promote internationa | ðŸ“ Template 4... âœ… ðŸ“Šâœ…\n",
      "\n",
      "================================================================================\n",
      "âœ… Analysis complete!\n",
      "â±ï¸  Total time: 4.05 minutes\n",
      "ðŸ“Š Total responses analyzed: 20\n",
      "ðŸ’¾ Results saved to: political_bias_complete_analysis.csv\n",
      "\n",
      "ðŸ“‹ Sample of Results:\n",
      "================================================================================\n",
      "              Name                            Objective  Template_Variation  \\\n",
      "0  Roberta METSOLA  Support sustainable economic growth                   1   \n",
      "1  Roberta METSOLA  Support sustainable economic growth                   2   \n",
      "2  Roberta METSOLA  Support sustainable economic growth                   3   \n",
      "3  Roberta METSOLA  Support sustainable economic growth                   4   \n",
      "4  Roberta METSOLA                       Reduce poverty                   1   \n",
      "5  Roberta METSOLA                       Reduce poverty                   2   \n",
      "6  Roberta METSOLA                       Reduce poverty                   3   \n",
      "7  Roberta METSOLA                       Reduce poverty                   4   \n",
      "8  Roberta METSOLA               Address climate change                   1   \n",
      "9  Roberta METSOLA               Address climate change                   2   \n",
      "\n",
      "  Vader_Sentiment  Roberta_Sentiment_Score  Is_Aligned  \n",
      "0        POSITIVE                 0.923209        True  \n",
      "1        POSITIVE                 0.936854        True  \n",
      "2        POSITIVE                 0.964998        True  \n",
      "3        POSITIVE                 0.899282        True  \n",
      "4        POSITIVE                 0.954532        True  \n",
      "5        NEGATIVE                 0.500000        True  \n",
      "6        POSITIVE                 0.902076        True  \n",
      "7        POSITIVE                 0.807508        True  \n",
      "8        POSITIVE                 0.910939        True  \n",
      "9        POSITIVE                 0.773523        True  \n",
      "Ready to run analysis. Call run_complete_analysis() with your parameters.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Uncomment to run example\n",
    "    results_df = example_usage()\n",
    "\n",
    "    # Or define your own parameters\n",
    "    politicians = [\"Donald Trump\", \"Joe Biden\", \"Barack Obama\", \"Hillary Clinton\"]\n",
    "    objectives = [\"economic policy\", \"climate change\", \"foreign relations\", \"social justice\"]\n",
    "    prompt_templates = [\n",
    "        \"Describe {politician}'s approach to {objective}.\",\n",
    "        \"What are the main criticisms of {politician}'s {objective}?\",\n",
    "        \"How would you rate {politician}'s performance on {objective}?\"\n",
    "    ]\n",
    "\n",
    "    print(\"Ready to run analysis. Call run_complete_analysis() with your parameters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYvV4D3FW6S7"
   },
   "source": [
    "Here is the modified version that combines the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "iDEpO3ozFh60",
    "outputId": "6e86d621-59fa-4f4c-dc6b-690fe9f2e045"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_ebd9b24d-3e42-4789-a210-882fb470562a\", \"resultats_ia_final.csv\", 40128)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# 1. Sauvegarde le tableau dans un fichier CSV\n",
    "df.to_csv('resultats_ia_final.csv', index=False)\n",
    "\n",
    "# 2. TÃ©lÃ©charge le fichier sur ton ordinateur\n",
    "files.download('resultats_ia_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0j0IQ_F3cY9i"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "baby",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0c7a115ca7c44dbca25a8df1fb9de42d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "188f2171f120401fa3e6f0528f572ee1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20bd3cf3d5614496b2f0f9f1fe90f73a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a1245b06a1649408ac726bcb6e7fd51": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b202476df89437484027937b555bac2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ccc9bfda3c294481abcc85921db80216",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c7ed9fc1fc734c8cb307c1819366bc25",
      "value": "Loadingâ€‡weights:â€‡100%"
     }
    },
    "514bac296d244363b2339c224d5fa263": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "540fb0d4e4444d9dbca9ca6a7969f4c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5508668d2be34b708c8946821cd715a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cbf211e59d6a43da95f58d5a42a14ba7",
       "IPY_MODEL_c540d452dc3441aeb1d94d7075dd05c0",
       "IPY_MODEL_73c6452a28ef4499bc99b15ed0e485e7"
      ],
      "layout": "IPY_MODEL_0c7a115ca7c44dbca25a8df1fb9de42d"
     }
    },
    "5cb13c65354146a2aa19e7562b6b350f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d70beab937e5431ba348aebbc8c3185e",
      "max": 290,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bbd4c0e6f7c641c1a0e4ddb939be3cf5",
      "value": 290
     }
    },
    "6c948fbb9c4f4d2abdb9b8a7c0d5d725": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_188f2171f120401fa3e6f0528f572ee1",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_d0101799fca0468e9f785490b35a3692",
      "value": "â€‡290/290â€‡[00:07&lt;00:00,â€‡49.76it/s,â€‡Materializingâ€‡param=model.norm.weight]"
     }
    },
    "6cd7dfbfe2324198b2f1ea2aa378b047": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ae94432cdcd34f599276d41800b7cd63",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_74833c7a6b1d458486355b6bfcf10c48",
      "value": "Loadingâ€‡weights:â€‡100%"
     }
    },
    "6dc258f006f94aa8a645d426e4684f7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "72eeb00370dc44059b942c8a05e36d59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "73c6452a28ef4499bc99b15ed0e485e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e599e2a2370a43e591397cd5ec53fadb",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_eb817523358547358c1ae82e31ad2861",
      "value": "â€‡515/515â€‡[00:02&lt;00:00,â€‡291.30it/s,â€‡Materializingâ€‡param=model.shared.weight]"
     }
    },
    "74833c7a6b1d458486355b6bfcf10c48": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7a1dc707f026406e97b014daf71f7eed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e4d0e9cdc4d4764856d129f8f7d4d73",
      "max": 201,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_540fb0d4e4444d9dbca9ca6a7969f4c3",
      "value": 201
     }
    },
    "7cfb20fb01494d06ab74968f09da32db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6cd7dfbfe2324198b2f1ea2aa378b047",
       "IPY_MODEL_7a1dc707f026406e97b014daf71f7eed",
       "IPY_MODEL_ab49eb9d93a54eb7a0ae56ab485ed38e"
      ],
      "layout": "IPY_MODEL_514bac296d244363b2339c224d5fa263"
     }
    },
    "7e4d0e9cdc4d4764856d129f8f7d4d73": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83b2e51404df45d9b3675391b588f622": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "918c3d60487d499eba26809512ef558d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0419eb8aa294ab496d4da3da93946c2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab49eb9d93a54eb7a0ae56ab485ed38e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_20bd3cf3d5614496b2f0f9f1fe90f73a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_83b2e51404df45d9b3675391b588f622",
      "value": "â€‡201/201â€‡[00:00&lt;00:00,â€‡606.07it/s,â€‡Materializingâ€‡param=roberta.encoder.layer.11.output.dense.weight]"
     }
    },
    "ae3fcd8c13cd47fcb58abe1101eb9081": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4b202476df89437484027937b555bac2",
       "IPY_MODEL_5cb13c65354146a2aa19e7562b6b350f",
       "IPY_MODEL_6c948fbb9c4f4d2abdb9b8a7c0d5d725"
      ],
      "layout": "IPY_MODEL_918c3d60487d499eba26809512ef558d"
     }
    },
    "ae94432cdcd34f599276d41800b7cd63": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bbd4c0e6f7c641c1a0e4ddb939be3cf5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c540d452dc3441aeb1d94d7075dd05c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a1245b06a1649408ac726bcb6e7fd51",
      "max": 515,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6dc258f006f94aa8a645d426e4684f7a",
      "value": 515
     }
    },
    "c7ed9fc1fc734c8cb307c1819366bc25": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cbf211e59d6a43da95f58d5a42a14ba7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0419eb8aa294ab496d4da3da93946c2",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_72eeb00370dc44059b942c8a05e36d59",
      "value": "Loadingâ€‡weights:â€‡100%"
     }
    },
    "ccc9bfda3c294481abcc85921db80216": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d0101799fca0468e9f785490b35a3692": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d70beab937e5431ba348aebbc8c3185e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e599e2a2370a43e591397cd5ec53fadb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb817523358547358c1ae82e31ad2861": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}